{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0OWEUWs7TJvx"
      },
      "source": [
        "## Step 1: Extract frames from video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "OPnW-qAyTNvU"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracted 1 frames to data\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "MAX_FRAMES = 78000\n",
        "def extract_frames(video_path, output_folder, num_frames=1):\n",
        "    # Open the video file\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    if not cap.isOpened():\n",
        "        print(\"Error: Could not open video.\")\n",
        "        return\n",
        "\n",
        "    # Get total number of frames\n",
        "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "    # Ensure output directory exists\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "    # Select 120 evenly spaced frame indices\n",
        "    frame_indices = np.linspace(0, total_frames - 1, num_frames, dtype=int)\n",
        "\n",
        "    count = 0\n",
        "    for i in frame_indices:\n",
        "        cap.set(cv2.CAP_PROP_POS_FRAMES, i)\n",
        "        ret, frame = cap.read()\n",
        "        if ret:\n",
        "            frame_path = os.path.join(output_folder, f'frame_{count:03d}.png')\n",
        "            cv2.imwrite(frame_path, frame)\n",
        "            count += 1\n",
        "        else:\n",
        "            print(f\"Warning: Could not read frame at index {i}\")\n",
        "\n",
        "    # Release video capture\n",
        "    cap.release()\n",
        "    print(f\"Extracted {count} frames to {output_folder}\")\n",
        "\n",
        "\n",
        "video_path = \"20211021_HR13_1_test_converted.mp4\"\n",
        "output_folder = \"data\"\n",
        "\n",
        "extract_frames(video_path, output_folder)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDzlV9XEemRq"
      },
      "source": [
        "## Step 2: Apply Thresholding to clean the images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2sdBELnbdtFZ",
        "outputId": "9ade4563-34b2-4106-f9b4-896915a7208b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Thresholding applied.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "input_folder = 'data'\n",
        "output_folder = 'masked_data'\n",
        "\n",
        "# Create output folder if it doesn't exist\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# Threshold for dark gray (everything <= this will be black)\n",
        "threshold = 90\n",
        "\n",
        "# Process all images\n",
        "for filename in os.listdir(input_folder):\n",
        "    if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff')):\n",
        "        input_path = os.path.join(input_folder, filename)\n",
        "        output_path = os.path.join(output_folder, filename)\n",
        "\n",
        "        # Open image in grayscale\n",
        "        img = Image.open(input_path).convert('L')\n",
        "        img_array = np.array(img)\n",
        "\n",
        "        # Pixels <= 50 → black (0), others → white (255)\n",
        "        thresholded_array = np.where(img_array <= threshold, 0, 255).astype(np.uint8)\n",
        "\n",
        "        # Save the result\n",
        "        thresholded_img = Image.fromarray(thresholded_array)\n",
        "        thresholded_img.save(output_path)\n",
        "\n",
        "print(\"Thresholding applied.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PUNS_enleKMI"
      },
      "source": [
        "## Step 3: Color surface"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ixPwgLvKdk2y"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from PIL import Image, ImageDraw\n",
        "\n",
        "# Paths\n",
        "input_folder = 'masked_data'           \n",
        "output_folder = 'masked_data'   \n",
        "\n",
        "# Create output folder if it doesn't exist\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "blue = (0, 0, 255)\n",
        "\n",
        "# Loop through all images in the input folder\n",
        "for filename in os.listdir(input_folder):\n",
        "    if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff')):\n",
        "        input_path = os.path.join(input_folder, filename)\n",
        "        output_path = os.path.join(output_folder, filename)\n",
        "\n",
        "        # Open image\n",
        "        with Image.open(input_path) as img:\n",
        "            img = img.convert('RGB')  # Ensure it's in RGB\n",
        "            width, height = img.size\n",
        "            start_y = int(height * 0.67)  # Bottom 30% starts here\n",
        "\n",
        "            # Draw blue rectangle over the bottom 30%\n",
        "            draw = ImageDraw.Draw(img)\n",
        "            draw.rectangle([0, start_y, width, height], fill=blue)\n",
        "\n",
        "            # Save the result\n",
        "            img.save(output_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GybnZ72xiCm7"
      },
      "source": [
        "## Step 4: Color the droplet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hqEV8eMDhPRB",
        "outputId": "c61f4647-5bbe-4e16-9016-78da67407e6b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dark pixels colored magenta (blue preserved). Saved in 'masked_data'\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# Colors in BGR\n",
        "MAGENTA = (255, 0, 255)\n",
        "\n",
        "# Threshold for \"dark\" pixels (R, G, B all <= this)\n",
        "dark_threshold = 50\n",
        "\n",
        "for filename in os.listdir(input_folder):\n",
        "    if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff')):\n",
        "        input_path = os.path.join(input_folder, filename)\n",
        "        output_path = os.path.join(output_folder, filename)\n",
        "\n",
        "        # Load image in full color (keep blue surface)\n",
        "        img = cv2.imread(input_path)\n",
        "\n",
        "        # Find dark pixels: where all channels are <= threshold\n",
        "        dark_mask = np.all(img <= dark_threshold, axis=-1)\n",
        "\n",
        "        # Color those pixels magenta\n",
        "        img[dark_mask] = MAGENTA\n",
        "\n",
        "        # Save result\n",
        "        Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB)).save(output_path)\n",
        "\n",
        "print(\"Dark pixels colored magenta (blue preserved). Saved in 'masked_data'\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6yMPaqXqGq0"
      },
      "source": [
        "## Step 5: Fill droplet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uwmf9EqUqFLy",
        "outputId": "8e4f5cff-de11-49f4-be21-4182e4ea6dbf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Filled droplet, applied neighborhood rules, and removed small blobs.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# Define colors in BGR\n",
        "MAGENTA = np.array([255, 0, 255])\n",
        "BLUE = np.array([255, 0, 0])\n",
        "WHITE = np.array([255, 255, 255])\n",
        "\n",
        "def create_mask(img, color, tolerance=30):\n",
        "    lower = np.clip(color - tolerance, 0, 255)\n",
        "    upper = np.clip(color + tolerance, 0, 255)\n",
        "    return cv2.inRange(img, lower, upper)\n",
        "\n",
        "for filename in os.listdir(input_folder):\n",
        "    if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff')):\n",
        "        img_path = os.path.join(input_folder, filename)\n",
        "        save_path = os.path.join(output_folder, filename)\n",
        "\n",
        "        img = cv2.imread(img_path)\n",
        "\n",
        "        # --- Step 1: Fill the droplet using contour ---\n",
        "        magenta_mask = create_mask(img, MAGENTA, tolerance=30)\n",
        "        contours, _ = cv2.findContours(magenta_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "        cv2.drawContours(img, contours, -1, MAGENTA.tolist(), thickness=cv2.FILLED)\n",
        "\n",
        "        # --- Step 2: Neighborhood Rules ---\n",
        "\n",
        "        # Recalculate masks\n",
        "        magenta_mask = create_mask(img, MAGENTA, tolerance=30) // 255\n",
        "        blue_mask = create_mask(img, BLUE, tolerance=30) // 255\n",
        "        white_mask = create_mask(img, WHITE, tolerance=30) // 255\n",
        "\n",
        "        # Rule 1: White pixel with magenta above AND blue below → becomes magenta\n",
        "        magenta_top_kernel = np.array([\n",
        "            [1, 1, 1],\n",
        "            [0, 0, 0],\n",
        "            [0, 0, 0]\n",
        "        ], dtype=np.uint8)\n",
        "\n",
        "        blue_bottom_kernel = np.array([\n",
        "            [0, 0, 0],\n",
        "            [0, 0, 0],\n",
        "            [1, 1, 1]\n",
        "        ], dtype=np.uint8)\n",
        "\n",
        "        magenta_top_neighbors = cv2.filter2D(magenta_mask, -1, magenta_top_kernel)\n",
        "        blue_bottom_neighbors = cv2.filter2D(blue_mask, -1, blue_bottom_kernel)\n",
        "\n",
        "        white_pixels = (white_mask == 1)\n",
        "        condition_fill = (magenta_top_neighbors >= 2) & (blue_bottom_neighbors >= 2)\n",
        "        img[np.logical_and(white_pixels, condition_fill)] = MAGENTA\n",
        "\n",
        "        # Rule 2: Magenta pixel with many white + some blue → becomes white\n",
        "        kernel = np.ones((3, 3), np.uint8)\n",
        "        white_neighbors = cv2.filter2D(white_mask, -1, kernel)\n",
        "        blue_neighbors = cv2.filter2D(blue_mask, -1, kernel)\n",
        "\n",
        "        magenta_pixels = (magenta_mask == 1)\n",
        "        condition_empty = np.logical_and(white_neighbors >= 4, blue_neighbors >= 1)\n",
        "        img[np.logical_and(magenta_pixels, condition_empty)] = WHITE\n",
        "\n",
        "        # --- Step 3: Keep only largest magenta region (remove little blobs) ---\n",
        "        post_magenta_mask = create_mask(img, MAGENTA, 30)\n",
        "        num_labels, labels, stats, _ = cv2.connectedComponentsWithStats(post_magenta_mask)\n",
        "        if num_labels > 1:\n",
        "            largest_label = 1 + np.argmax(stats[1:, cv2.CC_STAT_AREA])\n",
        "            cleaned_mask = (labels == largest_label).astype(np.uint8) * 255\n",
        "\n",
        "            # Reset all magenta to white\n",
        "            img[post_magenta_mask > 0] = WHITE\n",
        "            # Restore only the main droplet\n",
        "            img[cleaned_mask == 255] = MAGENTA\n",
        "\n",
        "        # --- Save result ---\n",
        "        Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB)).save(save_path)\n",
        "\n",
        "print(\"Filled droplet, applied neighborhood rules, and removed small blobs.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FuvuEooknbSC"
      },
      "source": [
        "## Step 6: Dataset preparation: U-Net / DeepLabV3+ / YOLACT (Object Segmentation)\n",
        "\n",
        "These models use:\n",
        "- 📄 1 image = input image\n",
        "- 🎨 1 label mask = multi-class\n",
        "\n",
        "We will use 1 grayscale mask with 3 class labels:\n",
        "- 0 = background\n",
        "- 1 = droplet\n",
        "- 2 = surface"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XMRVd-g8whld",
        "outputId": "c8ece894-4d30-4cff-8d1d-7f7cbb973109"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Grayscale segmentation masks saved in 'segmentation_masks'\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "input_folder = 'masked_data'\n",
        "output_folder = 'segmentation_masks'\n",
        "\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# BGR colors\n",
        "MAGENTA = np.array([255, 0, 255])\n",
        "BLUE = np.array([255, 0, 0])\n",
        "WHITE = np.array([255, 255, 255])\n",
        "\n",
        "def create_mask(img, color, tolerance=30):\n",
        "    lower = np.clip(color - tolerance, 0, 255)\n",
        "    upper = np.clip(color + tolerance, 0, 255)\n",
        "    return cv2.inRange(img, lower, upper)\n",
        "\n",
        "for filename in os.listdir(input_folder):\n",
        "    if filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "        img_path = os.path.join(input_folder, filename)\n",
        "        img = cv2.imread(img_path)\n",
        "\n",
        "        # Create grayscale mask\n",
        "        mask = np.zeros(img.shape[:2], dtype=np.uint8)\n",
        "\n",
        "        droplet_mask = create_mask(img, MAGENTA) > 0\n",
        "        surface_mask = create_mask(img, BLUE) > 0\n",
        "        # print(f\"{filename} → droplet: {np.sum(droplet_mask)}, surface: {np.sum(surface_mask)}\")\n",
        "\n",
        "        mask[droplet_mask] = 1  # class 1: droplet\n",
        "        mask[surface_mask] = 2  # class 2: surface\n",
        "        # background stays 0\n",
        "\n",
        "        out_path = os.path.join(output_folder, os.path.splitext(filename)[0] + \"_mask.png\")\n",
        "        Image.fromarray(mask).save(out_path)\n",
        "\n",
        "print(\"Grayscale segmentation masks saved in 'segmentation_masks'\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sArdwHej6Yt_"
      },
      "source": [
        "#### _Prepare binary masks for droplet and surface_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WSpCb3Fl2pET",
        "outputId": "52c62623-3851-4fc6-c974-f8e4e3c5c463"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Binary droplet/surface masks saved with white foreground\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "input_folder = 'segmentation_masks'\n",
        "droplet_output = 'droplet_masks'\n",
        "surface_output = 'surface_masks'\n",
        "\n",
        "os.makedirs(droplet_output, exist_ok=True)\n",
        "os.makedirs(surface_output, exist_ok=True)\n",
        "\n",
        "for filename in os.listdir(input_folder):\n",
        "    if filename.endswith('_mask.png'):\n",
        "        path = os.path.join(input_folder, filename)\n",
        "        mask = np.array(Image.open(path))\n",
        "\n",
        "        # Droplet mask: white (255) where mask == 1\n",
        "        droplet_mask = np.where(mask == 1, 255, 0).astype(np.uint8)\n",
        "        Image.fromarray(droplet_mask).save(os.path.join(droplet_output, filename))\n",
        "\n",
        "        # Surface mask: white (255) where mask == 2\n",
        "        surface_mask = np.where(mask == 2, 255, 0).astype(np.uint8)\n",
        "        Image.fromarray(surface_mask).save(os.path.join(surface_output, filename))\n",
        "\n",
        "print(\"Binary droplet/surface masks saved with white foreground\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yo__1C7_6e-k"
      },
      "source": [
        "## Step 7: Dataset preparation: YOLO / R-CNN / Faster R-CNN (Object Detection)\n",
        "\n",
        "These models need:\n",
        "- 📄 Bounding boxes around each object\n",
        "- 🏷️ Separate .txt or .xml (YOLO/COCO/VOC) label files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2SV_z7K06_HS"
      },
      "source": [
        "### Prepare YOLO\n",
        "**Class IDs are converted**: 1 → 0 for droplet, 2 → 1 for surface (YOLO expects 0-based IDs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yH12s0-I5Smv",
        "outputId": "50b1f1b7-a337-4e9a-838e-58df2a4a3707"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "YOLO labels generated in 'yolo_labels'\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "label_mask_folder = 'segmentation_masks'\n",
        "image_folder = 'data'\n",
        "output_label_folder = 'yolo_labels'\n",
        "\n",
        "os.makedirs(output_label_folder, exist_ok=True)\n",
        "\n",
        "# Image size is needed for normalization\n",
        "for filename in os.listdir(label_mask_folder):\n",
        "    if filename.endswith('_mask.png'):\n",
        "        mask_path = os.path.join(label_mask_folder, filename)\n",
        "        img_name = filename.replace('_mask.png', '.png')\n",
        "        img_path = os.path.join(image_folder, img_name)\n",
        "\n",
        "        # Load grayscale mask and original image to get size\n",
        "        mask = np.array(Image.open(mask_path))\n",
        "        img = Image.open(img_path)\n",
        "        img_w, img_h = img.size\n",
        "\n",
        "        annotations = []\n",
        "\n",
        "        for class_id in [1, 2]:  # droplet and surface\n",
        "            # Find where this class is in the mask\n",
        "            coords = np.column_stack(np.where(mask == class_id))\n",
        "            if coords.size == 0:\n",
        "                continue  # no object of this class\n",
        "\n",
        "            y_min, x_min = coords.min(axis=0)\n",
        "            y_max, x_max = coords.max(axis=0)\n",
        "\n",
        "            # Convert to YOLO format (normalized center x/y, width, height)\n",
        "            x_center = ((x_min + x_max) / 2) / img_w\n",
        "            y_center = ((y_min + y_max) / 2) / img_h\n",
        "            box_width = (x_max - x_min) / img_w\n",
        "            box_height = (y_max - y_min) / img_h\n",
        "\n",
        "            annotations.append(f\"{class_id - 1} {x_center:.6f} {y_center:.6f} {box_width:.6f} {box_height:.6f}\")\n",
        "\n",
        "        # Write .txt label\n",
        "        label_path = os.path.join(output_label_folder, img_name.replace('.png', '.txt'))\n",
        "        with open(label_path, 'w') as f:\n",
        "            f.write(\"\\n\".join(annotations))\n",
        "\n",
        "print(\"YOLO labels generated in 'yolo_labels'\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9ZIVfs47y3r"
      },
      "source": [
        "### Convert masks into COCO format for R-CNN / Faster R-CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dDXqJ-Y97M_O",
        "outputId": "a17afe59-d53c-4ca5-e21b-1b37d77053f2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 120/120 [00:02<00:00, 54.86it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "COCO JSON annotations saved to coco_annotations.json\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import json\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "label_mask_folder = 'segmentation_masks'   # grayscale masks with 0/1/2\n",
        "image_folder = 'data'               # original RGB images\n",
        "output_json = 'coco_annotations.json'\n",
        "\n",
        "# COCO structure\n",
        "coco = {\n",
        "    \"images\": [],\n",
        "    \"annotations\": [],\n",
        "    \"categories\": [\n",
        "        {\"id\": 1, \"name\": \"droplet\"},\n",
        "        {\"id\": 2, \"name\": \"surface\"}\n",
        "    ]\n",
        "}\n",
        "\n",
        "annotation_id = 1\n",
        "image_id = 1\n",
        "\n",
        "for filename in tqdm(os.listdir(label_mask_folder)):\n",
        "    if not filename.endswith('_mask.png'):\n",
        "        continue\n",
        "\n",
        "    mask_path = os.path.join(label_mask_folder, filename)\n",
        "    img_name = filename.replace('_mask.png', '.png')\n",
        "    img_path = os.path.join(image_folder, img_name)\n",
        "\n",
        "    # Load\n",
        "    mask = np.array(Image.open(mask_path))\n",
        "    img = Image.open(img_path)\n",
        "    width, height = img.size\n",
        "\n",
        "    # Add image info\n",
        "    coco['images'].append({\n",
        "        \"file_name\": img_name,\n",
        "        \"height\": height,\n",
        "        \"width\": width,\n",
        "        \"id\": image_id\n",
        "    })\n",
        "\n",
        "    for class_id in [1, 2]:  # droplet, surface\n",
        "        positions = np.column_stack(np.where(mask == class_id))\n",
        "        if positions.size == 0:\n",
        "            continue\n",
        "\n",
        "        y_min, x_min = positions.min(axis=0)\n",
        "        y_max, x_max = positions.max(axis=0)\n",
        "        box_width = x_max - x_min\n",
        "        box_height = y_max - y_min\n",
        "\n",
        "        # COCO expects [x, y, width, height]\n",
        "        coco['annotations'].append({\n",
        "            \"id\": annotation_id,\n",
        "            \"image_id\": image_id,\n",
        "            \"category_id\": class_id,\n",
        "            \"bbox\": [int(x_min), int(y_min), int(box_width), int(box_height)],\n",
        "            \"area\": int(box_width * box_height),\n",
        "            \"iscrowd\": 0\n",
        "        })\n",
        "        annotation_id += 1\n",
        "\n",
        "    image_id += 1\n",
        "\n",
        "# Save\n",
        "with open(output_json, 'w') as f:\n",
        "    json.dump(coco, f, indent=4)\n",
        "\n",
        "print(f\"COCO JSON annotations saved to {output_json}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### _Save all the data_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u4bZYFFL8Fp_"
      },
      "outputs": [],
      "source": [
        "!zip -r processed_data.zip . -x \"*/sample_data/*\""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
